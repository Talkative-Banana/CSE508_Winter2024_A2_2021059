# -*- coding: utf-8 -*-
"""Assignment2_IR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m_BnvTuLMx_tXtdNtUIeQZhZo2ok9BHy
"""

# Set up CUDA in OS
import os
import math
import heapq
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
# Import libabries
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import seaborn as sn
import pandas as pd
import torchvision
from torchvision import *
from torch.utils.data import Dataset, DataLoader
from torchvision.io import read_image
import torchvision.transforms as T
from torchvision import datasets, models, transforms
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

import matplotlib.pyplot as plt
import time
import copy
from PIL import Image
import pickle
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import multiprocessing
from urllib import error
from urllib import request
from PIL import Image
from io import BytesIO

import nltk
import csv
nltk.download('stopwords')
nltk.download('punkt')

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

# Link to dataset
assignment = "/content/drive/MyDrive/Assignment_2_IR/Assignment_2/"
revdataset = "/content/drive/MyDrive/Assignment_2_IR/Assignment_2/dataset/reviews/"
imgdataset = "/content/drive/MyDrive/Assignment_2_IR/Assignment_2/dataset/images/"

# Create transform function
transforms_train = transforms.Compose([
    transforms.Resize((224, 224)),   #must same as here
    # transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(), # data augmentation
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization
])

def ExtractFeatures(model, image_tensor):
  resnet_features = torch.nn.Sequential(*list(model.children())[:-1])
  resnet_features.eval()
  with torch.no_grad():
    features = resnet_features(image_tensor)
    mean = torch.mean(features, dim=1, keepdim=True)
    std = torch.std(features, dim=1, keepdim=True)

    # Normalize features
    normalized_features = (features - mean) / (std + 1e-6)
  return normalized_features

def PreprocessImage_Extractfeatures(query, model, mode):
  results = {}
  if mode == "preprocess":
    for filename in os.listdir(imgdataset):
      # Load and preprocess the image
      image_path = imgdataset + filename
      image = Image.open(image_path)
      pil_image_rgb = image.convert('RGB')
      image_ = transforms_train(pil_image_rgb).unsqueeze(0)  # Add batch dimension
      results[filename] = np.squeeze(ExtractFeatures(model, image_))
      # if(filename == "654_1.jpg"): print(results[filename])

    results_file = assignment + "ImageFeatures.obj"
    # Save results to a file using pickle
    with open(results_file, 'wb') as f:
      pickle.dump(results, f)
    print("Images Preprocessing and Features results saved to:", results_file)
    return results
  else:
      try:
          response = request.urlopen(query)
          image_data = response.read()
      except:
          print('Warning: Could not download image')
          return 1
      pil_image = Image.open(BytesIO(image_data))
      pil_image_rgb = pil_image.convert('RGB')
      pil_image_rgb.save("tempdwn.jpg", format='JPEG', quality=90)
      image = Image.open("tempdwn.jpg")
      pil_image_rgb = image.convert('RGB')
      image_ = transforms_train(pil_image_rgb).unsqueeze(0)  # Add batch dimension
      res = np.squeeze(ExtractFeatures(model, image_))
      return res

def TF_IDF(dfs, tfs):
  # Calculate tf-idf for each term
  results = {}
  for token in tfs:
    tf = tfs[token]
    df = dfs[token] if token in dfs else 1
    results[token] = tf * math.log(1000 / df)
  return results

def PreprocessTexts_IDF(query, mode, TFDF):
  tfidf = {}
  results = {}
  Tfs = {}
  if(mode == "preprocess"):
    for filename in os.listdir(revdataset):
      key = int(filename[:-4])
      review_path = revdataset + filename
      f = open(review_path, "r").read()
      # Lowering the letters
      a = f.lower()
      # Breaking in Tokens
      tokens = word_tokenize(a)
      stop_words = set(stopwords.words('english'))
      # Removing stop_words
      tokens = [token for token in tokens if token not in stop_words]
      # Removing punctuations
      tokens = [token for token in tokens if token not in string.punctuation]
      # Removing blank space tokens
      tokens = [token for token in tokens if token.strip()]

      # Calculate frequency of each token
      freq = {}
      for token in tokens:
        if token not in freq:
          freq[token] = 1
        else:
          freq[token] += 1

      # For each token
      tf  = {}
      Len = len(tokens)
      for token in freq:
        tf[token] = freq[token] / Len
      Tfs[key] = tf

      for token in freq:
        if token not in results:
          results[token] = 1
        else:
          results[token] += 1

    for filename in os.listdir(revdataset):
      key = int(filename[:-4])
      tfidf[key] = TF_IDF(results, Tfs[key])

    results_file = assignment + "TF_IDF.obj"
    # Save results to a file using pickle
    with open(results_file, 'wb') as f:
      pickle.dump(tfidf, f)

    results_file1 = assignment + "Dict.obj"
    # Save results to a file using pickle
    with open(results_file1, 'wb') as f:
      pickle.dump(results, f)

    print("Images Preprocessing and TF-IDF results saved to:", results_file)
    return tfidf, results
  else:
    a = query.lower()
    # Breaking in Tokens
    tokens = word_tokenize(a)
    stop_words = set(stopwords.words('english'))
    # Removing stop_words
    tokens = [token for token in tokens if token not in stop_words]
    # Removing punctuations
    tokens = [token for token in tokens if token not in string.punctuation]
    # Removing blank space tokens
    tokens = [token for token in tokens if token.strip()]

    # Calculate frequency of each token
    freq = {}
    for token in tokens:
      if token not in freq:
        freq[token] = 1
      else:
        freq[token] += 1

    # For each token
    tf  = {}
    Len = len(tokens)
    for token in freq:
      tf[token] = freq[token] / Len
    tfidf = TF_IDF(TFDF, tf)
  return tfidf

def read_csv_to_dict(csv_file, col1, col2):
    data_dict = {}
    with open(csv_file, 'r') as file:
        reader = csv.reader(file)
        next(reader)  # Skip the header row
        for row in reader:
            if len(row) >= 3:  # Checking if the row has at least 2 columns
                key = row[col1].strip()  # Value of the first column
                if(col2 == 1): value = eval(row[col2].strip())  # Value of the second column
                else: value = row[col2].strip()
                data_dict[key] = value
    return data_dict

def tfdfcosinesim(dict1, dict2):
  sum = 0
  sum1 = 0
  sum2 = 0
  for key in dict1:
    if key in dict2:
      sum += dict1[key] * dict2[key]

  for key in dict1:
    sum1 += dict1[key] * dict1[key]

  for key in dict2:
    sum2 += dict2[key] * dict2[key]

  sum1 = math.sqrt(sum1)
  sum2 = math.sqrt(sum2)
  if ((sum1 == 0) or (sum2 == 0)): return 0
  return sum / (sum1 * sum2)

def Images(image_tensor, features):
  h = []
  feature2 = np.squeeze(image_tensor)
  for image in features:
    feature1 = np.squeeze(features[image])
    x = cosinesim(feature1, feature2)
    heapq.heappush(h, (x, image))

  top20 = heapq.nlargest(20, h)
  top3_imgs = []
  docs = {}
  i = 0
  while((i < 20) and (len(top3_imgs) < 3)):
    if top20[i][1].split('_')[0] not in docs:
      docs[top20[i][1].split('_')[0]] = 1
      top3_imgs.append(top20[i])
    i += 1
  return top3_imgs

def Reviews(tfdf_review, keyreview):
  h = []
  for r in keyreview:
    review = keyreview[r]
    x = tfdfcosinesim(review, tfdf_review)
    heapq.heappush(h, (x, r))

  top20 = heapq.nlargest(20, h)
  top3_revs = []
  docs = {}
  i = 0
  while((i < 20) and (len(top3_revs) < 3)):
    if top20[i][1] not in docs:
      docs[top20[i][1]] = 1
      top3_revs.append(top20[i])
    i += 1

  return top3_revs

def cosinesim(tensor1, tensor2):
  tensor1 = np.array(tensor1)
  tensor2 = np.array(tensor2)
  len1 = len(tensor1)
  len2 = len(tensor2)
  if(len1 != len2):
    print("Invalid Vector Size")
    return 1
  else:
    sum = 0
    sum1 = 0
    sum2 = 0
    for x, y in zip(tensor1, tensor2):
      sum  += x * y
      sum1 += x * x
      sum2 += y * y
    if((sum1 == 0) or (sum2 == 0)): return 0
  return (sum / (math.sqrt(sum1) * math.sqrt(sum2)))

def Result_Img(top3, keyimage, keyreview, tfdf_review, tfdf):
  # top3 [[cosine, image.jpg], [cosine, image.jpg]]
  combined_score = []
  print("USING IMAGE RETRIEVAL")
  for rank in range(1, len(top3) + 1):
    key = top3[rank - 1][1].split('_')[0]
    imgsim = top3[rank - 1][0]
    revsim = tfdfcosinesim(tfdf[int(key)], tfdf_review)
    print(f"{rank}) Image URL: ", keyimage[key])
    print("Review: ", keyreview[key])
    print("Cosine similarity of image [Image used for ranking]: ", imgsim)
    print("Cosine similarity of text - ", revsim)
    print("Composite similarity score: ", (revsim + imgsim) / 2)
    combined_score.append([(revsim + imgsim) / 2, int(key)])
    print()
  return combined_score

def Result_Rev(top3, keyimage, keyreview, feature2, model):
  # top3 [[cosine, image.jpg], [cosine, image.jpg]]
  combined_score = []
  print("USING TEXT RETRIEVAL")
  for rank in range(1, len(top3) + 1):
    key = str(top3[rank - 1][1])
    imgsim = cosinesim(PreprocessImage_Extractfeatures(keyimage[key][0], model, "query"), feature2)
    revsim = top3[rank - 1][0]
    print(f"{rank}) Image URL: ", keyimage[key])
    print("Review: ", keyreview[key])
    print("Cosine similarity of image [First Image from list]: ", imgsim)
    print("Cosine similarity of text - ", revsim)
    print("Composite similarity score: ", (revsim + imgsim) / 2)
    combined_score.append([(revsim + imgsim) / 2, int(key)])
    print()
  return combined_score

def Result_Comb(top3_comb, keyimage, keyreview, feature2, model, tfdf_review, tfdf):
    # top3 [[cosine, image.jpg], [cosine, image.jpg]]
    print("USING COMBINED RETRIEVAL")
    for rank in range(1, len(top3_comb) + 1):
      key = str(top3_comb[rank - 1][1])
      if(top3_comb[rank - 1][-1] == "I"):
        imgsim = cosinesim(PreprocessImage_Extractfeatures(keyimage[key][0], model, "query"), feature2)
        revsim = top3_comb[rank - 1][0]
        print(f"{rank}) Image URL: ", keyimage[key])
        print("Review: ", keyreview[key])
        # print("Cosine similarity of image [First Image from list]: ", imgsim)
        # print("Cosine similarity of text - ", (2 * revsim) - imgsim)
        print("Composite similarity score: ", revsim)
        print()
      else:
        imgsim = top3_comb[rank - 1][0]
        revsim = tfdfcosinesim(tfdf[int(key)], tfdf_review)
        print(f"{rank}) Image URL: ", keyimage[key])
        print("Review: ", keyreview[key])
        # print("Cosine similarity of image [Image used for ranking]: ", revsim)
        # print("Cosine similarity of text - ", (2 * imgsim) - revsim)
        print("Composite similarity score: ", imgsim)
        print()
    return

def main():
  np.random.seed(42)
  torch.manual_seed(42)
  # Mappings
  keyimage  = read_csv_to_dict(assignment + "A2_Data.csv", 0, 1)
  keyreview = read_csv_to_dict(assignment + "A2_Data.csv", 0, 2)
  # Model
  model = models.resnet18(pretrained=True)
  # Pre Processing and Extracting features from Images
  features = None
  if os.path.exists(assignment + "ImageFeatures.obj"):
    with open(assignment + "ImageFeatures.obj", 'rb') as file:
        features = pickle.load(file)
  else:
    features = PreprocessImage_Extractfeatures(None, model, "preprocess")

  tfdf = None
  result = None
  # Pre Processing and Computing TF-IDF of Reviews
  if os.path.exists(assignment + "TF_IDF.obj"):
    with open(assignment + "TF_IDF.obj", 'rb') as file:
        tfdf = pickle.load(file)
  else:
    res = PreprocessTexts_IDF(None, "preprocess", None)
    tfdf = res[0]
    result = res[1]

  if os.path.exists(assignment + "Dict.obj"):
    with open(assignment + "Dict.obj", 'rb') as file:
        result = pickle.load(file)

  # Input Image Link
  imglink = input("Enter Image link: ")
  image_tensor = PreprocessImage_Extractfeatures(imglink, model, "query")
  # Input Review
  review  = input("Enter Review: ")
  tfdf_review = PreprocessTexts_IDF(review, "query", result)
  feature2 = np.squeeze(image_tensor)

  top3_imgs = Images(image_tensor, features)

  comb_img = Result_Img(top3_imgs, keyimage, keyreview, tfdf_review, tfdf)

  top3_revs = Reviews(tfdf_review, tfdf)

  comb_rev = Result_Rev(top3_revs, keyimage, keyreview, feature2, model)

  for v in comb_img: v.append("I")
  for v in comb_rev: v.append("R")

  comb = comb_rev + comb_img
  comb.sort(reverse = True)

  d = {}
  top3_comb = []
  for x in comb:
    if x[1] not in d:
      d[x[1]] = 1
      top3_comb.append(x)
  top3_comb = top3_comb[:3]

  Result_Comb(top3_comb, keyimage, keyreview, feature2, model, tfdf_review, tfdf)

  # https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg
  # I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.

main()